{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Bidirectional, Merge, Dropout, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.regularizers import l2\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import SVG, Image\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "[S&P 500 (^GSPC)](https://finance.yahoo.com/quote/%5EGSPC/history?period1=-631184400&period2=1499612400&interval=1d&filter=history&frequency=1d) 에서 1950/01/01 부터 07/07/2017년까지의 데이터를 받았습니다.<br>\n",
    "테스트용으로서 Dataset전체에 대해서 standardization을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 38\n",
    "LAG_SIZE = 1\n",
    "TRAINING_SIZE = 400\n",
    "\n",
    "raw_data = pd.read_csv('./GSPC.csv')\n",
    "raw_data['Date'] = pd.to_datetime(raw_data['Date'])\n",
    "# raw_data = raw_data[::-1]\n",
    "\n",
    "def preprocess(data):\n",
    "    X_COLUMNS = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    Y_COLUMNS = ['y']\n",
    "    COLUMNS = X_COLUMNS + Y_COLUMNS\n",
    "    \n",
    "    # Standardization\n",
    "    scaler = StandardScaler()\n",
    "    data[X_COLUMNS] = scaler.fit_transform(data[X_COLUMNS])\n",
    "    \n",
    "    # Create Y\n",
    "    # 반드시 Standardization이후에 와야 함\n",
    "    data['y'] = data.Close.shift(-1)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # BATCH\n",
    "    data = data[:data.shape[0]-data.shape[0]%BATCH_SIZE]\n",
    "    data = data[COLUMNS].as_matrix()\n",
    "\n",
    "    # Split X and Y\n",
    "    N = data.shape[0]-BATCH_SIZE -1\n",
    "    data_x = np.zeros((N, BATCH_SIZE, 5))\n",
    "    data_y = np.zeros((N, 1))\n",
    "    \n",
    "    for i in range(N):\n",
    "        end = i + BATCH_SIZE + 1\n",
    "        series = data[i:end]\n",
    "        \n",
    "        data_x[i, :] = series[:BATCH_SIZE, :-1].reshape(BATCH_SIZE, 5)\n",
    "        data_y[i] = series[BATCH_SIZE:, -1]\n",
    "    \n",
    "    return scaler, data_x, data_y\n",
    "\n",
    "def split_train_test(data_x, data_y, test_size=0.2):\n",
    "    train_size = int(data_y.shape[0] * (1-test_size))\n",
    "    \n",
    "    train_x, test_x = data_x[:train_size], data_x[train_size:]\n",
    "    train_y, test_y = data_y[:train_size], data_y[train_size:]\n",
    "        \n",
    "    return train_x, train_y, test_x, test_y\n",
    "    \n",
    "scaler, data_x, data_y = preprocess(raw_data)\n",
    "train_x, train_y, test_x, test_y = split_train_test(data_x, data_y)\n",
    "\n",
    "print('train_x:', train_x.shape)\n",
    "print('train_y:', train_y.shape)\n",
    "print('test_x :', test_x.shape)\n",
    "print('test_y :', test_y.shape)\n",
    "\n",
    "raw_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_data(x, y):\n",
    "    f, plots = subplots(4, 3)\n",
    "    f.set_figheight(5)\n",
    "    f.set_figwidth(14)\n",
    "    plots = plots.reshape(-1)\n",
    "    \n",
    "    for p in plots:\n",
    "        idx = np.random.randint(x.shape[0])\n",
    "        t = np.arange(BATCH_SIZE+1)\n",
    "        p.plot(t[:-1], x[idx, :, 3], label=\"x close\")\n",
    "        p.plot(t[-1], y[idx], label='y close', marker='o', color='red')\n",
    "        p.legend(loc='upper left')\n",
    "        p.grid()\n",
    "        \n",
    "visualize_data(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INPUT_N = train_x.shape[-1]\n",
    "def create_model(lstm_memory=64):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_memory, return_sequences=True, batch_input_shape=(None, BATCH_SIZE, INPUT_N)))\n",
    "    model.add(LSTM(lstm_memory, return_sequences=True))  # (2, 38, 64)\n",
    "    \n",
    "    model.add(Reshape((BATCH_SIZE*lstm_memory,), \n",
    "                      input_shape=(-1, BATCH_SIZE, lstm_memory)))  # (2, 1, 2432)\n",
    "    \n",
    "    model.add(Dense(2048))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1792))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "        \n",
    "    model.add(Dense(512, kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[mean_squared_error])\n",
    "    return model\n",
    "    \n",
    "model = create_model()\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, verbose=2, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def validate(x_train, y_train, x_test, y_test):\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    \n",
    "    train_n = y_train_pred.shape[0]\n",
    "    test_n = y_test_pred.shape[0]\n",
    "    x = np.arange(train_n + test_n)\n",
    "    \n",
    "    plot(x[:train_n], y_train, color='#555555')\n",
    "    plot(x[:train_n], y_train_pred)\n",
    "    \n",
    "    plot(x[train_n:], y_test, color='#555555')\n",
    "    plot(x[train_n:], y_test_pred, color='red')\n",
    "    \n",
    "    print('TRAIN r^2 score:', r2_score(y_train_pred, y_train))\n",
    "    print('TRAIN MSE score:', mse(y_train_pred, y_train))\n",
    "    \n",
    "    print('TEST  r^2 score:', r2_score(y_test_pred, y_test))\n",
    "    print('TRAIN MSE score:', mse(y_test_pred, y_test))\n",
    "    \n",
    "validate(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n",
    "```\n",
    " - epoch 10\n",
    " - mse\n",
    "\n",
    " - LSTM 64\n",
    " - LSTM 64\n",
    " - Reshape \n",
    " \n",
    " - 2048\n",
    " - batch\n",
    " - selu\n",
    " \n",
    " - 1280\n",
    " - batch\n",
    " - selu\n",
    " \n",
    " - 512\n",
    " - batch\n",
    " - selu\n",
    " \n",
    " - 256\n",
    " - batch\n",
    " - selu\n",
    " \n",
    " - 1\n",
    " \n",
    "TRAIN r^2 score: 0.985016345938 \n",
    "TRAIN MSE score: 0.00629689728654\n",
    "TEST  r^2 score: -0.929616577374\n",
    "TRAIN MSE score: 0.189794574429\n",
    "\n",
    "20번 돌리면\n",
    "TRAIN r^2 score: 0.987728857903\n",
    "TRAIN MSE score: 0.00501801610127\n",
    "TEST  r^2 score: -0.609017352468\n",
    "TRAIN MSE score: 0.230812901795\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
